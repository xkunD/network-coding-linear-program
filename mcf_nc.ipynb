{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution status: optimal\n",
      "Maximum concurrent flow: 0.7500\n",
      "\n",
      "Session 0: 0 → 2 (flow: 0.7500)\n",
      "  Path: 0 → 3 → 2, Flow: 0.3750\n",
      "  Path: 0 → 4 → 2, Flow: 0.3750\n",
      "  Total session flow: 0.7500\n",
      "\n",
      "Session 1: 1 → 0 (flow: 0.7500)\n",
      "  Path: 1 → 3 → 0, Flow: 0.3750\n",
      "  Path: 1 → 4 → 0, Flow: 0.3750\n",
      "  Total session flow: 0.7500\n",
      "\n",
      "Session 2: 2 → 1 (flow: 0.7500)\n",
      "  Path: 2 → 3 → 1, Flow: 0.3750\n",
      "  Path: 2 → 4 → 1, Flow: 0.3750\n",
      "  Total session flow: 0.7500\n",
      "\n",
      "Session 3: 3 → 4 (flow: 0.7500)\n",
      "  Path: 3 → 0 → 4, Flow: 0.2500\n",
      "  Path: 3 → 1 → 4, Flow: 0.2500\n",
      "  Path: 3 → 2 → 4, Flow: 0.2500\n",
      "  Total session flow: 0.7500\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class MaxConcurrentFlowSolver:\n",
    "    \"\"\"\n",
    "    Solver for maximum concurrent flow problems in undirected networks.\n",
    "    Finds the maximum flow that all sessions can achieve simultaneously.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, G: nx.Graph, sessions: List[Tuple[int, int]]):\n",
    "        \"\"\"\n",
    "        Initialize the solver with a network and sessions.\n",
    "        \n",
    "        Args:\n",
    "            G: NetworkX undirected graph with edge capacities stored as 'capacity' attribute\n",
    "            sessions: List of (source, target) tuples representing commodity flows\n",
    "        \"\"\"\n",
    "        self.G = G.copy()\n",
    "        self.sessions = sessions\n",
    "        self.num_nodes = G.number_of_nodes()\n",
    "        self.num_edges = G.number_of_edges()\n",
    "        self.num_commodities = len(sessions)\n",
    "        \n",
    "        # Store edges in a consistent order\n",
    "        self.edges = list(G.edges())\n",
    "        self.edge_index = {e: i for i, e in enumerate(self.edges)}\n",
    "        \n",
    "        # Add reverse edges to the edge index for undirected graph\n",
    "        for (u, v) in list(self.edge_index.keys()):\n",
    "            self.edge_index[(v, u)] = self.edge_index[(u, v)]\n",
    "        \n",
    "        # Extract edge capacities\n",
    "        self.capacities = np.array([G[u][v].get('capacity', float('inf')) for u, v in self.edges])\n",
    "        \n",
    "        # Create a directed graph for tracking flows (to handle edge directions properly)\n",
    "        self.flow_graph = nx.DiGraph()\n",
    "        for u, v in self.edges:\n",
    "            capacity = G[u][v].get('capacity', float('inf'))\n",
    "            self.flow_graph.add_edge(u, v, capacity=capacity)\n",
    "            self.flow_graph.add_edge(v, u, capacity=capacity)\n",
    "        \n",
    "        # Initialize results\n",
    "        self.flows = None\n",
    "        self.max_concurrent_flow = None\n",
    "        self.status = None\n",
    "    \n",
    "    def solve(self):\n",
    "        \"\"\"\n",
    "        Solve the maximum concurrent flow problem using linear programming.\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing solution status and optimal flows\n",
    "        \"\"\"\n",
    "        # Create flow variables for each commodity on each edge\n",
    "        # f[k][i][j] represents flow of commodity k on edge (i,j)\n",
    "        f = {}\n",
    "        for k in range(self.num_commodities):\n",
    "            f[k] = {}\n",
    "            for i in range(self.num_nodes):\n",
    "                f[k][i] = {}\n",
    "                for j in self.G.neighbors(i):\n",
    "                    f[k][i][j] = cp.Variable(nonneg=True)\n",
    "        \n",
    "        # Create variable for the maximum concurrent flow\n",
    "        # This represents how much flow each session can carry\n",
    "        mcf = cp.Variable(nonneg=True)\n",
    "        \n",
    "        # Objective: Maximize the concurrent flow\n",
    "        objective = cp.Maximize(mcf)\n",
    "        \n",
    "        # Constraints\n",
    "        constraints = []\n",
    "        \n",
    "        # 1. Capacity constraints for each edge (sum of all commodity flows <= edge capacity)\n",
    "        for u, v in self.edges:\n",
    "            edge_flow_sum = 0\n",
    "            for k in range(self.num_commodities):\n",
    "                edge_flow_sum += f[k][u][v] + f[k][v][u]  # Sum both directions for undirected\n",
    "            constraints.append(edge_flow_sum <= self.G[u][v].get('capacity', float('inf')))\n",
    "        \n",
    "        # 2. Flow conservation constraints\n",
    "        for k, (source, target) in enumerate(self.sessions):\n",
    "            for i in range(self.num_nodes):\n",
    "                if i != source and i != target:  # For intermediate nodes\n",
    "                    # Sum of incoming flows equals sum of outgoing flows\n",
    "                    flow_balance = 0\n",
    "                    for j in self.G.neighbors(i):\n",
    "                        flow_balance += f[k][j][i] - f[k][i][j]\n",
    "                    constraints.append(flow_balance == 0)\n",
    "        \n",
    "        # 3. Flow requirements - each session must achieve the mcf value\n",
    "        for k, (source, target) in enumerate(self.sessions):\n",
    "            # Calculate the net outflow at source\n",
    "            source_outflow = 0\n",
    "            for j in self.G.neighbors(source):\n",
    "                source_outflow += f[k][source][j] - f[k][j][source]\n",
    "            constraints.append(source_outflow == mcf)\n",
    "            \n",
    "            # The net inflow at target should equal the outflow at source\n",
    "            target_inflow = 0\n",
    "            for i in self.G.neighbors(target):\n",
    "                target_inflow += f[k][i][target] - f[k][target][i]\n",
    "            constraints.append(target_inflow == mcf)\n",
    "        \n",
    "        # Solve the problem\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve(solver=cp.ECOS)\n",
    "        \n",
    "        # Store results\n",
    "        self.status = problem.status\n",
    "        self.max_concurrent_flow = mcf.value\n",
    "        \n",
    "        # Extract flow values for each commodity on each edge\n",
    "        self.flows = {}\n",
    "        for k in range(self.num_commodities):\n",
    "            self.flows[k] = {}\n",
    "            for u in range(self.num_nodes):\n",
    "                for v in self.G.neighbors(u):\n",
    "                    if (u, v) not in self.flows[k]:\n",
    "                        # Get the flow values in both directions\n",
    "                        forward_flow = f[k][u][v].value\n",
    "                        backward_flow = f[k][v][u].value if v in f[k] and u in f[k][v] else 0\n",
    "                        \n",
    "                        # Calculate effective flow (can't have flow in both directions simultaneously)\n",
    "                        if forward_flow > backward_flow:\n",
    "                            self.flows[k][(u, v)] = forward_flow - backward_flow\n",
    "                            self.flows[k][(v, u)] = 0\n",
    "                        else:\n",
    "                            self.flows[k][(v, u)] = backward_flow - forward_flow\n",
    "                            self.flows[k][(u, v)] = 0\n",
    "        \n",
    "        return {\n",
    "            'status': self.status,\n",
    "            'max_concurrent_flow': self.max_concurrent_flow,\n",
    "            'flows': self.flows\n",
    "        }\n",
    "    \n",
    "    def get_flow_dict(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of flows for each session and edge.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: {session_idx: {(u, v): flow_value}}\n",
    "        \"\"\"\n",
    "        if self.flows is None:\n",
    "            raise ValueError(\"Problem must be solved before getting flows\")\n",
    "        return self.flows\n",
    "    \n",
    "    def visualize_network(self, figsize=(12, 8)):\n",
    "        \"\"\"\n",
    "        Visualize the network with edge capacities and optimal flows.\n",
    "        \"\"\"\n",
    "        if self.flows is None:\n",
    "            raise ValueError(\"Problem must be solved before visualization\")\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Create position layout\n",
    "        pos = nx.spring_layout(self.G, seed=42)\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(self.G, pos, node_size=500)\n",
    "        \n",
    "        # Draw edges with capacity labels\n",
    "        edge_labels = {(u, v): f\"cap: {self.G[u][v].get('capacity', '∞')}\" for u, v in self.edges}\n",
    "        nx.draw_networkx_edges(self.G, pos, width=1.0, alpha=0.5)\n",
    "        nx.draw_networkx_edge_labels(self.G, pos, edge_labels=edge_labels)\n",
    "        \n",
    "        # Draw node labels\n",
    "        nx.draw_networkx_labels(self.G, pos)\n",
    "        \n",
    "        # Add source and target information\n",
    "        for k, (source, target) in enumerate(self.sessions):\n",
    "            plt.annotate(f\"Session {k}: {source}→{target} (flow: {self.max_concurrent_flow:.4f})\",\n",
    "                        xy=(0, 0), xytext=(0, -30 - 10 * k),\n",
    "                        xycoords=('axes fraction'), textcoords='offset points',\n",
    "                        ha='left', va='top')\n",
    "        \n",
    "        plt.title(f\"Maximum Concurrent Flow: {self.max_concurrent_flow:.4f}\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def print_solution(self):\n",
    "        \"\"\"\n",
    "        Print the solution details.\n",
    "        \"\"\"\n",
    "        if self.flows is None:\n",
    "            raise ValueError(\"Problem must be solved before printing solution\")\n",
    "        \n",
    "        print(f\"Solution status: {self.status}\")\n",
    "        print(f\"Maximum concurrent flow: {self.max_concurrent_flow:.4f}\")\n",
    "        \n",
    "        for k, (source, target) in enumerate(self.sessions):\n",
    "            print(f\"\\nSession {k}: {source} → {target} (flow: {self.max_concurrent_flow:.4f})\")\n",
    "            \n",
    "            # Create a directed flow network for this commodity\n",
    "            flow_net = nx.DiGraph()\n",
    "            for u, v in self.G.edges():\n",
    "                flow_uv = self.flows[k].get((u, v), 0)\n",
    "                flow_vu = self.flows[k].get((v, u), 0)\n",
    "                \n",
    "                if flow_uv > 1e-6:\n",
    "                    flow_net.add_edge(u, v, flow=flow_uv)\n",
    "                if flow_vu > 1e-6:\n",
    "                    flow_net.add_edge(v, u, flow=flow_vu)\n",
    "            \n",
    "            # Find all simple paths from source to target in the flow network\n",
    "            try:\n",
    "                all_paths = list(nx.all_simple_paths(flow_net, source, target))\n",
    "                \n",
    "                # Calculate flow for each path\n",
    "                path_flows = []\n",
    "                remaining_flow = self.max_concurrent_flow\n",
    "                \n",
    "                for path in all_paths:\n",
    "                    if remaining_flow < 1e-6:\n",
    "                        break\n",
    "                        \n",
    "                    # Find the minimum flow on the path\n",
    "                    min_flow = float('inf')\n",
    "                    for i in range(len(path) - 1):\n",
    "                        u, v = path[i], path[i + 1]\n",
    "                        edge_flow = flow_net[u][v].get('flow', 0)\n",
    "                        min_flow = min(min_flow, edge_flow)\n",
    "                    \n",
    "                    # Skip paths with no flow\n",
    "                    if min_flow < 1e-6:\n",
    "                        continue\n",
    "                    \n",
    "                    # Adjust for remaining flow\n",
    "                    path_flow = min(min_flow, remaining_flow)\n",
    "                    path_flows.append((path, path_flow))\n",
    "                    remaining_flow -= path_flow\n",
    "                    \n",
    "                    # Reduce the flow on this path\n",
    "                    for i in range(len(path) - 1):\n",
    "                        u, v = path[i], path[i + 1]\n",
    "                        flow_net[u][v]['flow'] -= path_flow\n",
    "                \n",
    "                # Print paths\n",
    "                total_session_flow = 0\n",
    "                for path, flow in path_flows:\n",
    "                    print(f\"  Path: {' → '.join(map(str, path))}, Flow: {flow:.4f}\")\n",
    "                    total_session_flow += flow\n",
    "                \n",
    "                print(f\"  Total session flow: {total_session_flow:.4f}\")\n",
    "                \n",
    "            except nx.NetworkXNoPath:\n",
    "                print(f\"  No flow path found from {source} to {target}\")\n",
    "                print(f\"  Total session flow: 0.0000\")\n",
    "    \n",
    "    def visualize_flows(self, figsize=(15, 10)):\n",
    "        \"\"\"\n",
    "        Visualize the network with flows for each session.\n",
    "        \"\"\"\n",
    "        if self.flows is None:\n",
    "            raise ValueError(\"Problem must be solved before visualization\")\n",
    "        \n",
    "        # Create a separate visualization for each session\n",
    "        for k, (source, target) in enumerate(self.sessions):\n",
    "            plt.figure(figsize=figsize)\n",
    "            pos = nx.spring_layout(self.G, seed=42)\n",
    "            \n",
    "            # Create a directed graph for this commodity's flow\n",
    "            flow_graph = nx.DiGraph()\n",
    "            flow_graph.add_nodes_from(self.G.nodes())\n",
    "            \n",
    "            # Add edges with flow values\n",
    "            edge_colors = []\n",
    "            edge_widths = []\n",
    "            \n",
    "            for u, v in self.G.edges():\n",
    "                flow_uv = self.flows[k].get((u, v), 0)\n",
    "                flow_vu = self.flows[k].get((v, u), 0)\n",
    "                \n",
    "                if flow_uv > 1e-6:\n",
    "                    flow_graph.add_edge(u, v, weight=flow_uv)\n",
    "                    edge_colors.append(flow_uv)\n",
    "                    edge_widths.append(1 + 5 * flow_uv / self.max_concurrent_flow if self.max_concurrent_flow > 0 else 1)\n",
    "                \n",
    "                if flow_vu > 1e-6:\n",
    "                    flow_graph.add_edge(v, u, weight=flow_vu)\n",
    "                    edge_colors.append(flow_vu)\n",
    "                    edge_widths.append(1 + 5 * flow_vu / self.max_concurrent_flow if self.max_concurrent_flow > 0 else 1)\n",
    "            \n",
    "            # Draw the nodes\n",
    "            nx.draw_networkx_nodes(flow_graph, pos, node_size=700,\n",
    "                                  node_color=['red' if n == source else 'green' if n == target else 'lightblue' \n",
    "                                             for n in flow_graph.nodes()])\n",
    "            \n",
    "            # Draw the edges with flow\n",
    "            if flow_graph.edges():\n",
    "                edges = nx.draw_networkx_edges(flow_graph, pos, width=edge_widths, edge_color=edge_colors, \n",
    "                                             edge_cmap=plt.cm.Blues, edge_vmin=0, edge_vmax=self.max_concurrent_flow,\n",
    "                                             connectionstyle='arc3,rad=0.1')  # Curved edges for directed\n",
    "                \n",
    "                # Add a colorbar\n",
    "                sm = plt.cm.ScalarMappable(cmap=plt.cm.Blues, norm=plt.Normalize(0, self.max_concurrent_flow))\n",
    "                sm.set_array([])\n",
    "                cbar = plt.colorbar(sm)\n",
    "                cbar.set_label('Flow Amount')\n",
    "                \n",
    "                # Add edge labels with flow values\n",
    "                edge_labels = {(u, v): f\"{flow_graph[u][v]['weight']:.2f}\" for u, v in flow_graph.edges()}\n",
    "                nx.draw_networkx_edge_labels(flow_graph, pos, edge_labels=edge_labels, label_pos=0.3)\n",
    "            \n",
    "            # Draw node labels\n",
    "            nx.draw_networkx_labels(flow_graph, pos)\n",
    "            \n",
    "            # Set title\n",
    "            plt.title(f\"Session {k}: {source} → {target} (Flow: {self.max_concurrent_flow:.4f})\")\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def run_example():\n",
    "    # Create a sample network\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes and edges with capacities\n",
    "    edges = [\n",
    "        (0, 3, 1),\n",
    "        (0, 4, 1),\n",
    "        (3, 1, 1),\n",
    "        (1, 4, 1),\n",
    "        (3, 2, 1),\n",
    "        (2, 4, 1)\n",
    "    ]\n",
    "    for u, v, capacity in edges:\n",
    "        G.add_edge(u, v, capacity=capacity)\n",
    "    \n",
    "    # Define sessions: (source, target)\n",
    "    sessions = [\n",
    "        (0, 2),\n",
    "        (1, 0),\n",
    "        (2, 1),\n",
    "        (3, 4)\n",
    "    ]\n",
    "    \n",
    "    # Create and solve the maximum concurrent flow problem\n",
    "    solver = MaxConcurrentFlowSolver(G, sessions)\n",
    "    result = solver.solve()\n",
    "    \n",
    "    # Display results\n",
    "    solver.print_solution()\n",
    "    # solver.visualize_network()\n",
    "    # solver.visualize_flows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Network Capacity Analysis Results ======\n",
      "Network: 5 nodes, 6 edges\n",
      "Source-sink pairs: [('a', 'b'), ('b', 'c'), ('a', 'c'), ('d', 'e')]\n",
      "\n",
      "Maximum achievable rate: 1.0\n",
      "\n",
      "Key Variable Values:\n",
      "H(X1) = 1.0\n",
      "H(X2) = 1.0\n",
      "H(X3) = 1.0\n",
      "H(X4) = 1.0\n",
      "H_a_d = 1.0\n",
      "H_a_e = 0.0\n",
      "H_d_a = 0.0\n",
      "H_d_b = 0.0\n",
      "H_d_c = 1.0\n",
      "H_e_a = 1.0\n",
      "H_e_b = 1.0\n",
      "H_e_c = 0.0\n",
      "H_b_d = 1.0\n",
      "H_b_e = 0.0\n",
      "H_c_d = 0.0\n",
      "H_c_e = 1.0\n",
      "H_in_a = 1.0\n",
      "H_out_a = 0.0\n",
      "H_in_out_a = 1.0\n",
      "H_in_d = 2.0\n",
      "H_out_d = 0.0\n",
      "H_in_out_d = 2.0\n",
      "H_in_e = 1.0\n",
      "H_out_e = 0.0\n",
      "H_in_out_e = 1.0\n",
      "H_in_b = 1.0\n",
      "H_out_b = 0.0\n",
      "H_in_out_b = 1.0\n",
      "H_in_c = 1.0\n",
      "H_out_c = 0.0\n",
      "H_in_out_c = 1.0\n",
      "H_in_a_d = 2.0\n",
      "H_out_a_d = 0.0\n",
      "H_in_out_a_d = 2.0\n",
      "H_in_a_e = 1.0\n",
      "H_out_a_e = 0.0\n",
      "H_in_out_a_e = 1.0\n",
      "H_in_a_b = 2.0\n",
      "H_out_a_b = 0.0\n",
      "H_in_out_a_b = 2.0\n",
      "H_in_a_c = 2.0\n",
      "H_out_a_c = 0.0\n",
      "H_in_out_a_c = 2.0\n",
      "H_in_d_e = 3.0\n",
      "H_out_d_e = 0.0\n",
      "H_in_out_d_e = 0.0\n",
      "H_in_b_d = 2.0\n",
      "H_out_b_d = 0.0\n",
      "H_in_out_b_d = 2.0\n",
      "H_in_c_d = 2.0\n",
      "H_out_c_d = 0.0\n",
      "H_in_out_c_d = 2.0\n",
      "H_in_b_e = 1.0\n",
      "H_out_b_e = 0.0\n",
      "H_in_out_b_e = 1.0\n",
      "H_in_c_e = 1.0\n",
      "H_out_c_e = 0.0\n",
      "H_in_out_c_e = 1.0\n",
      "H_in_b_c = 2.0\n",
      "H_out_b_c = 0.0\n",
      "H_in_out_b_c = 2.0\n",
      "H_in_a_d_e = 2.0\n",
      "H_out_a_d_e = 0.0\n",
      "H_in_out_a_d_e = 2.0\n",
      "H_in_a_b_d = 2.0\n",
      "H_out_a_b_d = 0.0\n",
      "H_in_out_a_b_d = 2.0\n",
      "H_in_a_c_d = 2.0\n",
      "H_out_a_c_d = 0.0\n",
      "H_in_out_a_c_d = 2.0\n",
      "H_in_a_b_e = 1.0\n",
      "H_out_a_b_e = 0.0\n",
      "H_in_out_a_b_e = 1.0\n",
      "H_in_a_c_e = 1.0\n",
      "H_out_a_c_e = 0.0\n",
      "H_in_out_a_c_e = 1.0\n",
      "H_in_a_b_c = 3.0\n",
      "H_out_a_b_c = 0.0\n",
      "H_in_out_a_b_c = 0.0\n",
      "H_in_b_d_e = 2.0\n",
      "H_out_b_d_e = 0.0\n",
      "H_in_out_b_d_e = 2.0\n",
      "H_in_c_d_e = 2.0\n",
      "H_out_c_d_e = 0.0\n",
      "H_in_out_c_d_e = 2.0\n",
      "H_in_b_c_d = 2.0\n",
      "H_out_b_c_d = 0.0\n",
      "H_in_out_b_c_d = 2.0\n",
      "H_in_b_c_e = 1.0\n",
      "H_out_b_c_e = 0.0\n",
      "H_in_out_b_c_e = 1.0\n",
      "H_in_a_b_d_e = 1.0\n",
      "H_out_a_b_d_e = 0.0\n",
      "H_in_out_a_b_d_e = 1.0\n",
      "H_in_a_c_d_e = 1.0\n",
      "H_out_a_c_d_e = 0.0\n",
      "H_in_out_a_c_d_e = 1.0\n",
      "H_in_a_b_c_d = 2.0\n",
      "H_out_a_b_c_d = 0.0\n",
      "H_in_out_a_b_c_d = 2.0\n",
      "H_in_a_b_c_e = 1.0\n",
      "H_out_a_b_c_e = 0.0\n",
      "H_in_out_a_b_c_e = 1.0\n",
      "H_in_b_c_d_e = 1.0\n",
      "\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "from pulp import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EntropyCalculusAnalyzer:\n",
    "    \"\"\"\n",
    "    A general script for analyzing network capacity using entropy calculus.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.G = None  # Undirected graph\n",
    "        self.DG = None  # Directed graph\n",
    "        self.source_sink_pairs = []\n",
    "        self.entropy_vars = {}  # Dictionary to store all entropy variables\n",
    "        self.results = {}\n",
    "        \n",
    "    def create_network(self, edges, capacities=None):\n",
    "        \"\"\"\n",
    "        Create a network from a list of edges.\n",
    "        \n",
    "        Args:\n",
    "            edges: List of (u, v) tuples representing edges\n",
    "            capacities: Dictionary mapping edges to capacities, defaults to 1\n",
    "        \"\"\"\n",
    "        self.G = nx.Graph()\n",
    "        self.G.add_edges_from(edges)\n",
    "        \n",
    "        # Set capacities\n",
    "        if capacities:\n",
    "            for edge, capacity in capacities.items():\n",
    "                u, v = edge\n",
    "                self.G[u][v]['capacity'] = capacity\n",
    "        else:\n",
    "            # Default capacity is 1\n",
    "            nx.set_edge_attributes(self.G, 1, 'capacity')\n",
    "            \n",
    "        # Create directed version\n",
    "        self.DG = self._derive_directed_graph()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_source_sink_pairs(self, pairs):\n",
    "        \"\"\"\n",
    "        Set the source-sink pairs for the network.\n",
    "        \n",
    "        Args:\n",
    "            pairs: List of (source, sink) tuples\n",
    "        \"\"\"\n",
    "        self.source_sink_pairs = pairs\n",
    "        return self\n",
    "    \n",
    "    def _derive_directed_graph(self):\n",
    "        \"\"\"\n",
    "        Derive a directed graph by replacing each undirected edge\n",
    "        with two directed edges.\n",
    "        \"\"\"\n",
    "        DG = nx.DiGraph()\n",
    "        \n",
    "        # Add all nodes\n",
    "        DG.add_nodes_from(self.G.nodes)\n",
    "        \n",
    "        # Replace each undirected edge with two directed edges\n",
    "        for u, v, data in self.G.edges(data=True):\n",
    "            capacity = data.get('capacity', 1)\n",
    "            DG.add_edge(u, v, capacity=capacity)\n",
    "            DG.add_edge(v, u, capacity=capacity)\n",
    "        \n",
    "        return DG\n",
    "    \n",
    "    def get_all_cuts(self):\n",
    "        \"\"\"\n",
    "        Generate all possible cuts of the graph.\n",
    "        A cut is a partition of nodes into two sets.\n",
    "        \"\"\"\n",
    "        nodes = list(self.G.nodes)\n",
    "        cuts = []\n",
    "        \n",
    "        # Generate all possible subsets of nodes\n",
    "        for i in range(1, len(nodes)):\n",
    "            for subset in itertools.combinations(nodes, i):\n",
    "                S = set(subset)\n",
    "                S_complement = set(nodes) - S\n",
    "                cuts.append((S, S_complement))\n",
    "        \n",
    "        return cuts\n",
    "    \n",
    "    def get_incoming_edges(self, S):\n",
    "        \"\"\"Get incoming edges to a set of nodes in the directed graph.\"\"\"\n",
    "        incoming = []\n",
    "        for v in S:\n",
    "            for u in self.DG.predecessors(v):\n",
    "                if u not in S:\n",
    "                    incoming.append((u, v))\n",
    "        return incoming\n",
    "    \n",
    "    def get_outgoing_edges(self, S):\n",
    "        \"\"\"Get outgoing edges from a set of nodes in the directed graph.\"\"\"\n",
    "        outgoing = []\n",
    "        for u in S:\n",
    "            for v in self.DG.successors(u):\n",
    "                if v not in S:\n",
    "                    outgoing.append((u, v))\n",
    "        return outgoing\n",
    "    \n",
    "    def formulate_lp(self):\n",
    "        \"\"\"\n",
    "        Formulate a linear program for network capacity analysis.\n",
    "        \"\"\"\n",
    "        # Create LP problem\n",
    "        prob = LpProblem(\"Network_Capacity\", LpMaximize)\n",
    "        \n",
    "        # 1. Create variables for all sessions (source-sink pairs)\n",
    "        for i, (source, sink) in enumerate(self.source_sink_pairs):\n",
    "            var_name = f\"X{i+1}\"\n",
    "            self.entropy_vars[var_name] = LpVariable(var_name, lowBound=0)\n",
    "        \n",
    "        # 2. Create variables for all directed edges\n",
    "        for u, v in self.DG.edges():\n",
    "            var_name = f\"H_{u}_{v}\"\n",
    "            self.entropy_vars[var_name] = LpVariable(var_name, lowBound=0)\n",
    "        \n",
    "        # 3. Create variables for all subsets used in input-output inequalities\n",
    "        for S, S_complement in self.get_all_cuts():\n",
    "            in_edges = self.get_incoming_edges(S)\n",
    "            out_edges = self.get_outgoing_edges(S)\n",
    "            \n",
    "            # Create variable for in(S)\n",
    "            if in_edges:\n",
    "                in_S_name = f\"H_in_{'_'.join(sorted(S))}\"\n",
    "                self.entropy_vars[in_S_name] = LpVariable(in_S_name, lowBound=0)\n",
    "            \n",
    "            # Create variable for out(S)\n",
    "            if out_edges:\n",
    "                out_S_name = f\"H_out_{'_'.join(sorted(S))}\"\n",
    "                self.entropy_vars[out_S_name] = LpVariable(out_S_name, lowBound=0)\n",
    "            \n",
    "            # Create variable for in(S) U out(S)\n",
    "            if in_edges and out_edges:\n",
    "                both_S_name = f\"H_in_out_{'_'.join(sorted(S))}\"\n",
    "                self.entropy_vars[both_S_name] = LpVariable(both_S_name, lowBound=0)\n",
    "        \n",
    "        # 4. Set objective: maximize H(X1)\n",
    "        prob += self.entropy_vars[\"X1\"]\n",
    "        \n",
    "        # 5. Add constraint: all sessions have the same entropy\n",
    "        for i in range(2, len(self.source_sink_pairs) + 1):\n",
    "            prob += self.entropy_vars[f\"X{i}\"] == self.entropy_vars[\"X1\"]\n",
    "        \n",
    "        # 6. Add capacity constraints\n",
    "        for u, v in self.G.edges():\n",
    "            prob += (self.entropy_vars[f\"H_{u}_{v}\"] + self.entropy_vars[f\"H_{v}_{u}\"] \n",
    "                    <= self.G[u][v].get('capacity', 1))\n",
    "        \n",
    "        # 7. Add input-output inequalities for all cuts\n",
    "        for S, S_complement in self.get_all_cuts():\n",
    "            in_edges = self.get_incoming_edges(S)\n",
    "            out_edges = self.get_outgoing_edges(S)\n",
    "            \n",
    "            if in_edges and out_edges:\n",
    "                in_S_name = f\"H_in_{'_'.join(sorted(S))}\"\n",
    "                out_S_name = f\"H_out_{'_'.join(sorted(S))}\"\n",
    "                both_S_name = f\"H_in_out_{'_'.join(sorted(S))}\"\n",
    "                \n",
    "                # Define the variables' relationships with the edge variables\n",
    "                # in(S) = sum of entropies of incoming edges\n",
    "                prob += self.entropy_vars[in_S_name] <= sum(self.entropy_vars[f\"H_{u}_{v}\"] \n",
    "                                                          for u, v in in_edges)\n",
    "                \n",
    "                # out(S) = sum of entropies of outgoing edges\n",
    "                prob += self.entropy_vars[out_S_name] <= sum(self.entropy_vars[f\"H_{u}_{v}\"] \n",
    "                                                           for u, v in out_edges)\n",
    "                \n",
    "                # Input-output inequality: H(in(S), out(S)) <= H(in(S))\n",
    "                # This is equivalent to: H(out(S) | in(S)) = 0\n",
    "                # Which means: out(S) is a function of in(S)\n",
    "                prob += self.entropy_vars[both_S_name] <= self.entropy_vars[in_S_name]\n",
    "                \n",
    "                # Submodularity relationships for the cut\n",
    "                # prob += self.entropy_vars[both_S_name] >= self.entropy_vars[in_S_name]\n",
    "                # prob += self.entropy_vars[both_S_name] >= self.entropy_vars[out_S_name]\n",
    "        \n",
    "        # 8. Add submodularity constraints\n",
    "        # For each pair of variables S1, S2 where S1 is a subset of S2\n",
    "        # we add H(S1) <= H(S2)\n",
    "        \n",
    "        # For session variables in relation to edge variables\n",
    "        for i, (source, sink) in enumerate(self.source_sink_pairs):\n",
    "            var_name = f\"X{i+1}\"\n",
    "            \n",
    "            # Check which cuts have this session's source and sink separated\n",
    "            for S, S_complement in self.get_all_cuts():\n",
    "                if ((source in S and sink in S_complement) or \n",
    "                    (source in S_complement and sink in S)):\n",
    "                    \n",
    "                    # Session entropy should be <= entropy of edges crossing the cut\n",
    "                    in_edges = self.get_incoming_edges(S)\n",
    "                    out_edges = self.get_outgoing_edges(S)\n",
    "                    \n",
    "                    if in_edges and out_edges:\n",
    "                        both_S_name = f\"H_in_out_{'_'.join(sorted(S))}\"\n",
    "                        prob += self.entropy_vars[var_name] <= self.entropy_vars[both_S_name]\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def analyze_network(self):\n",
    "        \"\"\"\n",
    "        Analyze the network by formulating and solving the LP.\n",
    "        \"\"\"\n",
    "        # Formulate LP\n",
    "        prob = self.formulate_lp()\n",
    "        \n",
    "        # Solve with CBC solver\n",
    "        prob.solve(PULP_CBC_CMD(msg=False))\n",
    "        \n",
    "        # Store results\n",
    "        self.results['status'] = LpStatus[prob.status]\n",
    "        \n",
    "        if prob.status == LpStatusOptimal:\n",
    "            self.results['max_rate'] = value(prob.objective)\n",
    "            \n",
    "            # Store variable values\n",
    "            var_values = {}\n",
    "            for name, var in self.entropy_vars.items():\n",
    "                var_values[name] = var.value()\n",
    "            self.results['variables'] = var_values\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def visualize_network(self):\n",
    "        \"\"\"Visualize the network with source-sink pairs.\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        pos = nx.spring_layout(self.G)\n",
    "        \n",
    "        # Draw the network\n",
    "        nx.draw(self.G, pos, with_labels=True, node_color='lightblue', \n",
    "                node_size=500, font_weight='bold')\n",
    "        \n",
    "        # Add edge labels (capacities)\n",
    "        edge_labels = nx.get_edge_attributes(self.G, 'capacity')\n",
    "        nx.draw_networkx_edge_labels(self.G, pos, edge_labels=edge_labels)\n",
    "        \n",
    "        # Add a legend for source-sink pairs\n",
    "        for i, (s, t) in enumerate(self.source_sink_pairs):\n",
    "            plt.text(0.01, 0.95 - i*0.05, f\"X{i+1}: {s} → {t}\", \n",
    "                    transform=plt.gca().transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def print_results(self):\n",
    "        \"\"\"Print the analysis results.\"\"\"\n",
    "        print(\"\\n====== Network Capacity Analysis Results ======\")\n",
    "        print(f\"Network: {len(self.G.nodes)} nodes, {len(self.G.edges())} edges\")\n",
    "        print(f\"Source-sink pairs: {self.source_sink_pairs}\")\n",
    "        \n",
    "        if 'max_rate' in self.results:\n",
    "            print(f\"\\nMaximum achievable rate: {self.results['max_rate']}\")\n",
    "            \n",
    "            if 'variables' in self.results:\n",
    "                print(\"\\nKey Variable Values:\")\n",
    "                for i in range(len(self.source_sink_pairs)):\n",
    "                    print(f\"H(X{i+1}) = {self.results['variables'][f'X{i+1}']}\")\n",
    "                    \n",
    "                # Print a few edge entropy values as examples\n",
    "                count = 0\n",
    "                for edge, value in self.results['variables'].items():\n",
    "                    if edge.startswith(\"H_\") and \"_\" in edge and count < 100:\n",
    "                        print(f\"{edge} = {value}\")\n",
    "                        count += 1\n",
    "        \n",
    "        print(\"\\n===========================================\")\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create analyzer\n",
    "    analyzer = EntropyCalculusAnalyzer()\n",
    "    \n",
    "    # Example: Create K3,2 network\n",
    "    edges = [\n",
    "        ('a', 'd'), ('a', 'e'),\n",
    "        ('b', 'd'), ('b', 'e'),\n",
    "        ('c', 'd'), ('c', 'e')\n",
    "    ]\n",
    "    analyzer.create_network(edges)\n",
    "    \n",
    "    # Set source-sink pairs (cyclic configuration for K3,2)\n",
    "    pairs = [\n",
    "        ('a', 'b'),  # X1\n",
    "        ('b', 'c'),  # X2\n",
    "        ('a', 'c'),  # X3\n",
    "        ('d', 'e')   # X4\n",
    "    ]\n",
    "    analyzer.set_source_sink_pairs(pairs)\n",
    "    \n",
    "    # Visualize the network\n",
    "    # analyzer.visualize_network()\n",
    "    \n",
    "    # Analyze network\n",
    "    analyzer.analyze_network()\n",
    "    analyzer.print_results()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
